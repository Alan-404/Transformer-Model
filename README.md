# TRANSFORMER MODEL
<b>Reference</b>: <i>Attention is All You Need</i>, Google Brain Team

I. Model Architecture
<img src="./assets/Transformer.png"/>

II. Details
1. Attention Mechanism <br/>
<b>Code: </b> <a href="https://github.com/Alan-404/Transformer-Model/blob/master/model/utils/attention.py">Attention Code</a>
